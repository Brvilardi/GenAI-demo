{"cells":[{"cell_type":"markdown","source":["# **Resumo**\n","\n","A ideia do Projeto é utilizar técnicas de Inteligência Artificial com grandes modelos de linguagem (LLM) para construir um sistema de perguntas e respostas usando uma base de conhecimento de documentação de serviços da AWS."],"metadata":{"id":"1AJ7MPCLGKCx"}},{"cell_type":"markdown","source":["# **Descrição do Problema**\n","\n","Os LLMs são modelos que só tem conhecimento do que foi usado para os treinar. As documentações da AWS são atualizadas com muita frequência, por isso, usar LLMs para perguntas sobre serviços AWS pode não ser a melhor ideia, já que a resposta provavelmente estará desatualizada.\n","\n","\n"],"metadata":{"id":"i3PcvmiDGY0l"}},{"cell_type":"markdown","source":["# **Metodologia Aplicada**\n","\n","Baixamos os PDFs das documentações da AWS e armazenamos no S3, utilizamos a técnica RAG para construir um sistema que usa o contexto dos PDFs e da pergunta para gerar uma resposta baseada nos PDFs (mais detalhes sobre o processo estão descritos no Notebook).\n","\n","![Question](https://raw.githubusercontent.com/aws-samples/amazon-bedrock-workshop/b886384153a387218fe0fae175586aa8a061f86c/03_QuestionAnswering/images/Chatbot_lang.png)\n","\n","Basicamente, convertemos os PDFs em pedaços de texto (chunks), vetorizamos esses chunks e armazenamos em um VectorStore. Com isso, cada pergunta é vetorizada para buscarmos os chunks com contexto mais similar a pergunta (busca vetorial por similaridade) e usamos os chunks mais relevantes como contexto no prompt do LLM para que esse LLM responda a pergunta usando o contexto dos PDFs.\n","\n","### Técnicas utilizadas\n","- O armazenamento dos arquivos PDF foi feito utilizando o Amazon S3.\n","\n","- A geração de texto para interpretação da pergunta e elaboração da resposta foi feita utilizando Amazon Bedrock, rodando o modelo Cloude V2 da Anthropic.\n","\n","- Para agregar o conhecimento específico dos arquivos PDF no processo de geração da resposta utilizamos a técnica Retreival Augmented Generation (RAG).\n","\n","- A conversão dos textos em vetores foi feita usando o modelo Amazon Titan Embeddings G1 - Text, do Amazon Bedrock\n","\n","- O armazenamento dos vetores foi feito com a implementação FAISS\n","\n","- Para orquestrar esses processos, utilizamos a biblioteca [Langchain](https://python.langchain.com/docs/get_started/introduction).\n"],"metadata":{"id":"aYsDI7BEGysR"}},{"cell_type":"markdown","source":["# **Resultados**\n","\n","O sistema consegue gerar respostas a partir de uma pergunta usando apenas o contexto dos PDFs.\n","\n","Porém, converter os PDFs em chunks e criar os vetores destes chunks é muito demorado (para 4 arquivos levou 40 minutos), por isso ter um sistema produtivo que usa todas as documentações da AWS teria um desafio de aumentar a eficiência do processo para conseguir contar com mais documentações em um tempo razoável de processamento.\n","\n","Enquanto as perguntas são relacionadas aos serviços que estão na base de conhecimento, o sistema responde de forma coerente, porém, perguntas fora dos 4 serviços que usamos como base de conhecimento ou recebem um retorno que não há informações suficientes ou utiliza de menções desses serviços na documentações dos que estão na base (ex: Amazon Kinesis, que aparece da documentação do DynamoDB).\n","\n","\n"],"metadata":{"id":"9ZrYw9xfHkf8"}},{"cell_type":"markdown","source":["# **Conclusão**\n","\n","O projeto alcançou os resultados esperados, uma vez que foi capaz de responder perguntas com base no conhecimento das documentações da AWS. Porém, ele poderia ser melhorado com um sistema mais eficiênte de transformar o conteúdo das documentações em vetor para conseguirmos colocar mais arquivos de documentação e, com isso, o sistema conseguir responder sobre outros serviços da AWS.\n","\n","\n"],"metadata":{"id":"EpgoIA2KIWL4"}},{"cell_type":"markdown","source":["# **Referências**\n","\n","https://github.com/aws-samples/amazon-bedrock-workshop/tree/b886384153a387218fe0fae175586aa8a061f86c/03_QuestionAnswering\n","\n","\n","https://github.com/aws-samples/llm-apps-workshop/blob/main/blogs/rag/data_ingestion_to_vectordb.ipynb\n","\n","https://github.com/aws-samples/rag-using-langchain-amazon-bedrock-and-opensearch/blob/main/load-data-to-opensearch.py\n","\n","https://catalog.us-east-1.prod.workshops.aws/workshops/a4bdb007-5600-4368-81c5-ff5b4154f518/en-US/50-qa/52-rag-qa\n","\n","https://js.langchain.com/docs/get_started/introduction"],"metadata":{"id":"TIqtrfXMI1Ad"}},{"cell_type":"markdown","source":["# **Vídeo**\n","\n","Explicação completa do trabalho: https://www.youtube.com/watch?v=2q9uzgVZ0Sw (20 min)\n","\n","Demonstração do funcionamento: https://www.youtube.com/watch?v=Xfnm9IsjTeo (5 min)"],"metadata":{"id":"YWlnQXeaFJ7f"}},{"cell_type":"markdown","source":["# Implementação"],"metadata":{"id":"YsPNTNhqNNEC"}},{"cell_type":"markdown","metadata":{"id":"-_ls59TzW0Cn"},"source":["### Introdução\n","A ideia do Projeto é utilizar técnicas de Inteligência Artificial para construir um sistema de perguntas e respostas usando uma base de conhecimento de arquivos PDF que contém documentação de serviços da AWS.\n","\n","\n","### Técnicas utilizadas\n","- O armazenamento dos arquivos PDF foi feito utilizando o Amazon S3.\n","\n","- A geração de texto para interpretação da pergunta e elaboração da resposta foi feita utilizando Amazon Bedrock, rodando o modelo Cloude V2 da Anthropic.\n","\n","- Para agregar o conhecimento específico dos arquivos PDF no processo de geração da resposta utilizamos a técnica Retreival Augmented Generation (RAG).\n","\n","- Para orquestrar esses processos, utilizamos a biblioteca [Langchain](https://python.langchain.com/docs/get_started/introduction).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vQhSxn2932kn"},"source":["### Import das bibliotecas"]},{"cell_type":"markdown","source":["Instalar as bibliotecas necessárias"],"metadata":{"id":"1qEI9biOdMvA"}},{"cell_type":"code","source":["!pip install -q gwpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rh71QgR8dvsw","executionInfo":{"status":"ok","timestamp":1700576702916,"user_tz":180,"elapsed":8205,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"e0748b9b-e599-4667-eca1-9dfb75719869"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for ligo-segments (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34918,"status":"ok","timestamp":1700576737826,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"},"user_tz":180},"id":"Ecri9IXFXA0i","outputId":"9d725edd-cba1-4fcb-e66d-b645589a23f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 425 µs (started: 2023-11-21 14:25:37 +00:00)\n"]}],"source":["%%capture\n","!pip install ipython-autotime\n","!pip install --no-build-isolation --force-reinstall \\\n","    \"boto3>=1.28.57\" \\\n","    \"awscli>=1.29.57\" \\\n","    \"botocore>=1.31.57\"\n","!pip install --quiet \\\n","    langchain==0.0.309 \\\n","    \"faiss-cpu>=1.7,<2\" \\\n","    \"pypdf>=3.8,<4\"\n","\n","!pip install --quiet \\\n","    pandas_datareader  \\\n","    langchain_experimental \\\n","\n","%load_ext autotime\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1700576737827,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"},"user_tz":180},"id":"Ke-h1SM1W0Cp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d38426fd-a756-425c-b1d6-579e7f48623d"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 435 µs (started: 2023-11-21 14:25:37 +00:00)\n"]}],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"3zvSZyucuH46"},"source":["### Funções Úteis"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":392,"status":"ok","timestamp":1700576738194,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"},"user_tz":180},"id":"lnIuvKQSuHr6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0553026b-e111-4aeb-a3e7-0a346add8931"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 113 ms (started: 2023-11-21 14:25:37 +00:00)\n"]}],"source":["# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n","# SPDX-License-Identifier: MIT-0\n","\"\"\"Helper utilities for working with Amazon Bedrock from Python notebooks\"\"\"\n","# Python Built-Ins:\n","import os\n","from typing import Optional\n","\n","# External Dependencies:\n","import boto3\n","from botocore.config import Config\n","\n","\n","def get_bedrock_client(\n","    assumed_role: Optional[str] = None,\n","    region: Optional[str] = None,\n","    runtime: Optional[bool] = True,\n","):\n","    \"\"\"Create a boto3 client for Amazon Bedrock, with optional configuration overrides\n","\n","    Parameters\n","    ----------\n","    assumed_role :\n","        Optional ARN of an AWS IAM role to assume for calling the Bedrock service. If not\n","        specified, the current active credentials will be used.\n","    region :\n","        Optional name of the AWS Region in which the service should be called (e.g. \"us-east-1\").\n","        If not specified, AWS_REGION or AWS_DEFAULT_REGION environment variable will be used.\n","    runtime :\n","        Optional choice of getting different client to perform operations with the Amazon Bedrock service.\n","    \"\"\"\n","    if region is None:\n","        target_region = os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\"))\n","    else:\n","        target_region = region\n","\n","    print(f\"Create new client\\n  Using region: {target_region}\")\n","    session_kwargs = {\"region_name\": target_region}\n","    client_kwargs = {**session_kwargs}\n","\n","    profile_name = os.environ.get(\"AWS_PROFILE\")\n","    if profile_name:\n","        print(f\"  Using profile: {profile_name}\")\n","        session_kwargs[\"profile_name\"] = profile_name\n","\n","    retry_config = Config(\n","        region_name=target_region,\n","        retries={\n","            \"max_attempts\": 10,\n","            \"mode\": \"standard\",\n","        },\n","    )\n","    session = boto3.Session(**session_kwargs)\n","\n","    if assumed_role:\n","        print(f\"  Using role: {assumed_role}\", end='')\n","        sts = session.client(\"sts\")\n","        response = sts.assume_role(\n","            RoleArn=str(assumed_role),\n","            RoleSessionName=\"langchain-llm-1\"\n","        )\n","        print(\" ... successful!\")\n","        client_kwargs[\"aws_access_key_id\"] = response[\"Credentials\"][\"AccessKeyId\"]\n","        client_kwargs[\"aws_secret_access_key\"] = response[\"Credentials\"][\"SecretAccessKey\"]\n","        client_kwargs[\"aws_session_token\"] = response[\"Credentials\"][\"SessionToken\"]\n","\n","    if runtime:\n","        service_name='bedrock-runtime'\n","    else:\n","        service_name='bedrock'\n","\n","    bedrock_client = session.client(\n","        service_name=service_name,\n","        config=retry_config,\n","        **client_kwargs\n","    )\n","\n","    print(\"boto3 Bedrock client successfully created!\")\n","    print(bedrock_client._endpoint)\n","    return bedrock_client"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1700576738195,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"},"user_tz":180},"id":"uEFRj8K70qzf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d05b7100-ebe6-451c-a2ff-d5dd4552fbc3"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 653 µs (started: 2023-11-21 14:25:37 +00:00)\n"]}],"source":["from io import StringIO\n","import sys\n","import textwrap\n","\n","\n","def print_ww(*args, width: int = 100, **kwargs):\n","    \"\"\"Like print(), but wraps output to `width` characters (default 100)\"\"\"\n","    buffer = StringIO()\n","    try:\n","        _stdout = sys.stdout\n","        sys.stdout = buffer\n","        print(*args, **kwargs)\n","        output = buffer.getvalue()\n","    finally:\n","        sys.stdout = _stdout\n","    for line in output.splitlines():\n","        print(\"\\n\".join(textwrap.wrap(line, width=width)))"]},{"cell_type":"code","source":["def create_vector_embedding_with_bedrock(text, name, bedrock_client):\n","    payload = {\"inputText\": f\"{text}\"}\n","    body = json.dumps(payload)\n","    modelId = \"amazon.titan-embed-text-v1\"\n","    accept = \"application/json\"\n","    contentType = \"application/json\"\n","\n","    response = bedrock_client.invoke_model(\n","        body=body, modelId=modelId, accept=accept, contentType=contentType\n","    )\n","    response_body = json.loads(response.get(\"body\").read())\n","\n","    embedding = response_body.get(\"embedding\")\n","    return {\"_index\": name, \"text\": text, \"vector_field\": embedding}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XLEI6UQsRilG","executionInfo":{"status":"ok","timestamp":1700576738195,"user_tz":180,"elapsed":10,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"1bb5ccb2-2fb9-4a1e-de91-9d9b16ca071e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 429 µs (started: 2023-11-21 14:25:38 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"oanizWRRutyJ"},"source":["### Setup do client\n","\n","Configura o cliente do Bedrock com as credenciais de acesso da AWS."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1700576738195,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"},"user_tz":180},"id":"nE21nKOxW0Cq","outputId":"2ce81320-7893-4e39-fb9c-bf40c9b55892"},"outputs":[{"output_type":"stream","name":"stdout","text":["Create new client\n","  Using region: us-east-1\n","boto3 Bedrock client successfully created!\n","bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n","time: 98.5 ms (started: 2023-11-21 14:25:38 +00:00)\n"]}],"source":["import json\n","import os\n","import sys\n","\n","import boto3\n","\n","module_path = \"..\"\n","sys.path.append(os.path.abspath(module_path))\n","\n","\n","# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n","\n","os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"  # E.g. \"us-east-1\"\n","os.environ[\"AWS_ACCESS_KEY_ID\"] = \"AKIAYEFGZ2RHM35J4LA7\"\n","os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"1oAMky5SbMLJKQ4F5+aAzgl4vgGdtbWs6tK6aQSn\"\n","\n","\n","boto3_bedrock = get_bedrock_client()"]},{"cell_type":"markdown","metadata":{"id":"sQnlUAxdW0Cr"},"source":["## Setup do Langchain\n","\n","Instanciar o modelo de LLM e de Embeddings.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1175,"status":"ok","timestamp":1700576739363,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"},"user_tz":180},"id":"hbBUJAyOW0Cs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0fb3170b-59c4-44fe-9a39-eba5d60d07b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 807 ms (started: 2023-11-21 14:25:38 +00:00)\n"]}],"source":["from langchain.embeddings import BedrockEmbeddings\n","from langchain.llms.bedrock import Bedrock\n","\n","\n","llm = Bedrock(model_id=\"anthropic.claude-v2\", client=boto3_bedrock, model_kwargs={'max_tokens_to_sample':200})\n","bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=boto3_bedrock)"]},{"cell_type":"markdown","metadata":{"id":"zlm244ldW0Cs"},"source":["## Preparação dos dados"]},{"cell_type":"markdown","source":["#### Download dos arquivos do S3"],"metadata":{"id":"gzLzJNh6QpkK"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4544,"status":"ok","timestamp":1700576743903,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"},"user_tz":180},"id":"JmEHMfry3klB","outputId":"56b25d0b-fb60-42e5-90e3-17b71232c429"},"outputs":[{"output_type":"stream","name":"stdout","text":["Baixando o arquivo aurora-ug.pdf...\n","Baixando o arquivo dynamodb-dg.pdf...\n","Baixando o arquivo rds-ug.pdf...\n","Baixando o arquivo vpc-tm.pdf...\n","time: 4.97 s (started: 2023-11-21 14:25:38 +00:00)\n"]}],"source":["import boto3\n","from io import BytesIO\n","from pprint import pprint\n","\n","os.makedirs(\"data\", exist_ok=True)\n","\n","bucket_name =\"ciencia-de-dados-rag-t2\"\n","s3 = boto3.client('s3')\n","\n","bucket_objects = s3.list_objects(Bucket=bucket_name)['Contents']\n","\n","arquivos_pdf = []\n","\n","for obj in bucket_objects:\n","  obj_name = obj['Key']\n","  arquivos_pdf.append(obj_name)\n","  if not os.path.isfile(f'./data/{obj_name}'):\n","    print(f'Baixando o arquivo {obj_name}...')\n","    s3.download_file(bucket_name, obj_name, f'./data/{obj_name}')\n","  else:\n","    print(f'Arquivo {obj_name} já está baixado!')\n","\n"]},{"cell_type":"markdown","source":["### Vetorização dos arquivos\n","\n","Antes de responder as perguntas, os arquivos PDF precisam ser processados e armazenados em um banco de dados de vetor. Para isso, quebramos os arquivos em chunks e depois transformamos os textos em vetores, para armazenar essas informações em um banco de vetores (FAISS).\n","\n","![Embeddings](https://raw.githubusercontent.com/aws-samples/amazon-bedrock-workshop/b886384153a387218fe0fae175586aa8a061f86c/03_QuestionAnswering/images/Embeddings_lang.png)\n","\n","\n","\n","Basicamente, o processo é:\n","- Carregar os documentos do S3*\n","- Processar e separar em chunks menores\n","- Criar um vetor numérico que represente cada Chunk usando o modelo Amazon Bedrock Titan Embeddings\n","- Criar um index com esses chunks e seus correspondentes embeddings\n","\n","\n","*Após download, vamos carregar todos os arquivos do diretório usando o [DirectoryLoader from PyPDF available under LangChain](https://python.langchain.com/en/latest/reference/modules/document_loaders.html) e quebrar em chunks menores usando o [RecursiveCharacterTextSplitter](https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/recursive_text_splitter.html).\n","\n","O tamanho dos Chunks é uma decisão importante, pois ele deve ser grande suficiente para conter os contextos dos textos, porém pequeno suficiente para caber dentro do Prompt do LLM."],"metadata":{"id":"Hros593hQsv0"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":461573,"status":"ok","timestamp":1700577205472,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"},"user_tz":180},"id":"XrG0C6PzW0Cs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"632561f7-f634-44f9-85f2-01e21ddee3b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Average length among 7322 documents loaded is 2175 characters.\n","After the split we have 20597 documents more than the original 7322.\n","Average length among 20597 documents (after split) is 810 characters.\n","time: 7min 41s (started: 2023-11-21 14:25:43 +00:00)\n"]}],"source":["import numpy as np\n","from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n","from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n","\n","loader = PyPDFDirectoryLoader(\"./data/\")\n","\n","documents = loader.load()\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size = 1000,\n","    chunk_overlap  = 100,\n",")\n","docs = text_splitter.split_documents(documents)\n","\n","avg_doc_length = lambda documents: sum([len(doc.page_content) for doc in documents])//len(documents)\n","avg_char_count_pre = avg_doc_length(documents)\n","avg_char_count_post = avg_doc_length(docs)\n","print(f'Average length among {len(documents)} documents loaded is {avg_char_count_pre} characters.')\n","print(f'After the split we have {len(docs)} documents more than the original {len(documents)}.')\n","print(f'Average length among {len(docs)} documents (after split) is {avg_char_count_post} characters.')"]},{"cell_type":"code","source":["#Exemplo do conteúdo de um chunk\n","docs[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dVnL4xgcEACK","executionInfo":{"status":"ok","timestamp":1700583742776,"user_tz":180,"elapsed":296,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"f2fe8bb2-2bdc-4c31-dfb3-06d3ec0d70cb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Document(page_content='Amazon Aurora\\nUser Guide for Aurora', metadata={'source': 'data/aurora-ug.pdf', 'page': 0})"]},"metadata":{},"execution_count":30},{"output_type":"stream","name":"stdout","text":["time: 2.64 ms (started: 2023-11-21 16:22:22 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"dvvjWGm5W0Ct"},"source":["Exemplo de como ficaria um chunk vetorizado"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":462,"status":"ok","timestamp":1700577205908,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"},"user_tz":180},"id":"Du9J4hrIW0Ct","outputId":"3025f2af-d4f8-4b9d-d380-93c16e05ac92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Chunk:  Amazon Aurora\n","User Guide for Aurora \n","\n","\n","Amostra do chunk vetorizado:  [-0.16601562 -0.18261719  0.86328125 ... -0.21582031 -1.3515625\n"," -0.06884766] \n","\n","\n","Tamanho do embeddings:  (1536,)\n","time: 635 ms (started: 2023-11-21 14:33:25 +00:00)\n"]}],"source":["sample_embedding = np.array(bedrock_embeddings.embed_query(docs[0].page_content))\n","print(\"Chunk: \", docs[0].page_content, \"\\n\\n\")\n","\n","print(\"Amostra do chunk vetorizado: \", sample_embedding, \"\\n\\n\")\n","print(\"Tamanho do embeddings: \", sample_embedding.shape)"]},{"cell_type":"markdown","metadata":{"id":"B7n20Ff1W0Ct"},"source":["Como mostrado acima, vamos calcular os vetores para todos os chunks e armazenar em um storage de vetores.\n","\n","Isso será feito usando a implementação [FAISS](https://github.com/facebookresearch/faiss) do  [LangChain](https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/faiss.html)  que utiliza do modelo de embeddings (no caso o Bedrock Titan Embeddings) e a lista de chunks para criar o armazenamento de vetores.\n","\n","Após isso, criamos um Index para possibilitar as consultas semânticas em cima do storage de vetor. Para isso, usamos a implementação do [VectorStoreIndexWrapper](https://python.langchain.com/en/latest/modules/indexes/getting_started.html#one-line-index-creation).\n","\n","O FAISS é um vector store que fica armazenado em memória, para uma solução definitiva, poderíamos usar um serviço como OpenSearch para persistência dos vetores.\n","\n","**⚠️⚠️⚠️ NOTA: Como os PDF possuem muitas páginas, essa célula pode levar algumas horas para rodar ⚠️⚠️⚠️**"]},{"cell_type":"code","source":["len(docs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y0PGR5Zz01U4","executionInfo":{"status":"ok","timestamp":1700577212949,"user_tz":180,"elapsed":263,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"1ba4a614-b138-4346-f3de-1d87b21c2358"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20597"]},"metadata":{},"execution_count":13},{"output_type":"stream","name":"stdout","text":["time: 2.06 ms (started: 2023-11-21 14:33:32 +00:00)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c0_cTTdAW0Ct","executionInfo":{"status":"ok","timestamp":1700584637599,"user_tz":180,"elapsed":13963,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"1c238bda-e6cd-435c-9225-03d394af40d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 13.5 s (started: 2023-11-21 16:37:03 +00:00)\n"]}],"source":["from langchain.chains.question_answering import load_qa_chain\n","from langchain.vectorstores import FAISS\n","from langchain.indexes import VectorstoreIndexCreator\n","from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n","\n","vectorstore_faiss = FAISS.from_documents(\n","    docs[0:100],\n","    bedrock_embeddings,\n",")\n","\n","wrapper_store_faiss = VectorStoreIndexWrapper(vectorstore=vectorstore_faiss)"]},{"cell_type":"markdown","metadata":{"id":"KTIkvwf0W0Ct"},"source":["## Respondendo as perguntas\n","\n","Agora que já possuimos os arquivos vetorizados, podemos começar a fazer perguntas\n","\n","#### Fluxo da solução\n","![Question](https://raw.githubusercontent.com/aws-samples/amazon-bedrock-workshop/b886384153a387218fe0fae175586aa8a061f86c/03_QuestionAnswering/images/Chatbot_lang.png)\n","\n","O fluxo é:\n","- Criar um vetor com a pergunta\n","- Fazer uma busca no storage de vetor com o vetor da pergunta (busca semântica)\n","- Pega os top N chunks mais relevantes\n","- Adicionar esses chunks como parte do contexto do prompt da LLM\n","- Mandar o prompt para o LLM\n","- Recebe a resposta da LLM baseada nos documentos\n"]},{"cell_type":"markdown","source":["## Exemplos"],"metadata":{"id":"CPcKHEtYhwvW"}},{"cell_type":"markdown","source":["#### Pergunta sobre traffic mirroring"],"metadata":{"id":"Brr9Q6VRh8El"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6I5ccX76EC6l","executionInfo":{"status":"ok","timestamp":1700582806814,"user_tz":180,"elapsed":1079,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"a1e7b802-aba2-4105-d583-a8520d49e0dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 414 µs (started: 2023-11-21 16:06:45 +00:00)\n"]}],"source":["query = \"\"\"How does traffic mirroring works?\"\"\""]},{"cell_type":"markdown","metadata":{"id":"8FgvTNHOW0Cu"},"source":["Primeiro passo é criar um vetor da pergunta"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRqAmOXLW0Cu","executionInfo":{"status":"ok","timestamp":1700582807832,"user_tz":180,"elapsed":7,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"04081df7-faca-4822-a80a-f48e45253bda"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.49609375, -1.1875    ,  0.37695312, ...,  0.08349609,\n","       -0.3984375 ,  0.53125   ])"]},"metadata":{},"execution_count":16},{"output_type":"stream","name":"stdout","text":["time: 358 ms (started: 2023-11-21 16:06:46 +00:00)\n"]}],"source":["query_embedding = vectorstore_faiss.embedding_function(query)\n","np.array(query_embedding)"]},{"cell_type":"markdown","metadata":{"id":"fM8RCGMyW0Cu"},"source":["Com esse vetor, buscamos pelos chunks relevantes (vetores mais parecidos com o da pergunta)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5JMtFmP_W0Cu","executionInfo":{"status":"ok","timestamp":1700582807832,"user_tz":180,"elapsed":6,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"fc5aeafd-7b79-44d3-fd2e-e05b170dbccd"},"outputs":[{"output_type":"stream","name":"stdout","text":["4 documents are fetched which are relevant to the query.\n","----\n","## Document 1: 7. Choose Create .\n","Step 3: Create the traﬃc mirror session\n","Create a traﬃc mirror session that sends mirrored packets from the source to a target so that you\n","can\n","monitor and analyze traﬃc.\n","To create a traﬃc mirror session\n","1. In the navigation pane, choose Traﬃc Mirroring, Mirror sessions .\n","2. Choose Create traﬃc mirror session .\n","3. (Optional) For Name tag , enter a name for the traﬃc mirror session.\n","4. (Optional) For Description , enter a description for the traﬃc mirror session.\n","11.......\n","---\n","## Document 2: Amazon Virtual Private Cloud Traﬃc Mirroring\n","Targets\n","How Traﬃc Mirroring works\n","Traﬃc Mirroring copies inbound and outbound traﬃc from the network interfaces that are attached to\n","your instances. You can send the mirrored traﬃc to the network interface of another instance, a\n","Network\n","Load Balancer that has a UDP listener, or a Gateway Load Balancer that has a UDP listener. The traﬃc\n","mirror source and the traﬃc mirror target (monitoring appliance) can be in the same VPC. Or they can\n","be in a diﬀerent VPCs that are connected through intra-Region VPC peering, a transit gateway, or by\n","a\n","Gateway Load Balancer endpoint to connect to a Gateway Load Balancer in a diﬀerent VPC.\n","Consider the following scenario, where you mirror traﬃc from two sources (Source A and Source B) to\n","a\n","single traﬃc mirror target (Target D). After you create the traﬃc mirror session, any traﬃc that\n","matches\n","the ﬁlter rules is encapsulated in a VXLAN header. It is then sent to the target........\n","---\n","## Document 3: Amazon Virtual Private Cloud Traﬃc Mirroring\n","Traﬃc Mirroring concepts\n","What is Traﬃc Mirroring?\n","Traﬃc Mirroring is an Amazon VPC feature that you can use to copy network traﬃc from an elastic\n","network interface of type interface . You can then send the traﬃc to out-of-band security and\n","monitoring appliances for:\n","•Content inspection\n","•Threat monitoring\n","•Troubleshooting\n","The security and monitoring appliances can be deployed as individual instances, or as a ﬂeet of\n","instances\n","behind either a Network Load Balancer or a Gateway Load Balancer with a UDP listener. Traﬃc\n","Mirroring\n","supports ﬁlters and packet truncation, so that you can extract only the traﬃc of interest, using the\n","monitoring tools of your choice.\n","Traﬃc Mirroring concepts\n","The following are the key concepts for Traﬃc Mirroring:\n","•Source — The network interface to monitor.\n","•Filter  — A set of rules that deﬁnes the traﬃc that is mirrored.\n","•Target — The destination for mirrored traﬃc........\n","---\n","## Document 4: Amazon Virtual Private Cloud Traﬃc Mirroring\n","Traﬃc mirror sources\n","•A traﬃc mirror target (p. 3)\n","•A traﬃc mirror ﬁlter  (p. 7)\n","Each packet is mirrored once. However, you can use multiple traﬃc mirror sessions on the same mirror\n","source. This is useful if you want to send a subset of the mirrored traﬃc from a traﬃc mirror source\n","to multiple tools. For example, you can ﬁlter HTTP traﬃc in a higher priority traﬃc mirror session\n","and\n","send it to a speciﬁc monitoring appliance. At the same time, you can ﬁlter all other TCP traﬃc in a\n","lower\n","priority traﬃc mirror session and send it to another monitoring appliance.\n","Traﬃc mirror sources\n","A traﬃc mirror source is the network interface of type interface . For example, a network interface\n","for\n","an EC2 instance or an RDS instance.\n","A network interface can't be a traﬃc mirror target and a traﬃc mirror source in the same traﬃc\n","mirror\n","session.\n","Traﬃc Mirroring is not available on all instance types.\n","Instance types.......\n","---\n","time: 23.6 ms (started: 2023-11-21 16:06:47 +00:00)\n"]}],"source":["relevant_documents = vectorstore_faiss.similarity_search_by_vector(query_embedding)\n","print(f'{len(relevant_documents)} documents are fetched which are relevant to the query.')\n","print('----')\n","for i, rel_doc in enumerate(relevant_documents):\n","    print_ww(f'## Document {i+1}: {rel_doc.page_content}.......')\n","    print('---')"]},{"cell_type":"markdown","metadata":{"id":"ojbxEMiXW0Cu"},"source":["Agora basta usar a LLM para gerar uma resposta com base no contexto dos chunks mais parecidos com a pergunta.\n","\n","Para isso, usamos a implementação do Prompt template do Langchain.\n","\n","O Langchain possui uma abstração em cima do VectorStore que faz todo o processo acima e depois consulta a LLM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LIINpUJFW0Cu","executionInfo":{"status":"ok","timestamp":1700582807832,"user_tz":180,"elapsed":5,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"1eb540ee-7fe5-4202-d60e-6902f9a536df"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 887 µs (started: 2023-11-21 16:06:47 +00:00)\n"]}],"source":["from langchain.prompts import PromptTemplate\n","from langchain.chains import RetrievalQA\n","prompt_template = \"\"\"\n","\n","Human: Use the following pieces of context to provide a concise answer to the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n","<context>\n","{context}\n","</context\n","\n","Question: {question}\n","\n","Assistant:\"\"\"\n","\n","PROMPT = PromptTemplate(\n","    template=prompt_template, input_variables=[\"context\", \"question\"]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"etE3we4qW0Cu","executionInfo":{"status":"ok","timestamp":1700582814021,"user_tz":180,"elapsed":6192,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"1200dc96-37b6-43f2-c5d5-b24ca265373a"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'query': 'How does traffic mirroring works?', 'result': ' Based on the context, here is a summary\n","of how traffic mirroring works in Amazon VPC:\\n\\nTraffic mirroring copies inbound and outbound\n","traffic from network interfaces attached to instances. The mirrored traffic can be sent to the\n","network interface of another instance, a Network Load Balancer with a UDP listener, or a Gateway\n","Load Balancer with a UDP listener. \\n\\nThe traffic mirror source and target can be in the same or\n","different VPCs connected via VPC peering, transit gateway, or a Gateway Load Balancer. \\n\\nTraffic\n","matching the mirroring filter rules is encapsulated in a VXLAN header and sent to the target. This\n","allows out-of-band security and monitoring appliances to inspect, monitor, and troubleshoot the\n","mirrored traffic.', 'source_documents': [Document(page_content='7. Choose Create .\\nStep 3: Create\n","the traﬃc mirror session\\nCreate a traﬃc mirror session that sends mirrored packets from the source\n","to a target so that you can \\nmonitor and analyze traﬃc.\\nTo create a traﬃc mirror session\\n1. In\n","the navigation pane, choose Traﬃc Mirroring, Mirror sessions .\\n2. Choose Create traﬃc mirror\n","session .\\n3. (Optional) For Name tag , enter a name for the traﬃc mirror session.\\n4. (Optional)\n","For Description , enter a description for the traﬃc mirror session.\\n11', metadata={'source':\n","'data/vpc-tm.pdf', 'page': 14}), Document(page_content='Amazon Virtual Private Cloud Traﬃc\n","Mirroring\\nTargets\\nHow Traﬃc Mirroring works\\nTraﬃc Mirroring copies inbound and outbound traﬃc\n","from the network interfaces that are attached to \\nyour instances. You can send the mirrored traﬃc\n","to the network interface of another instance, a Network \\nLoad Balancer that has a UDP listener, or\n","a Gateway Load Balancer that has a UDP listener. The traﬃc \\nmirror source and the traﬃc mirror\n","target (monitoring appliance) can be in the same VPC. Or they can \\nbe in a diﬀerent VPCs that are\n","connected through intra-Region VPC peering, a transit gateway, or by a \\nGateway Load Balancer\n","endpoint to connect to a Gateway Load Balancer in a diﬀerent VPC.\\nConsider the following scenario,\n","where you mirror traﬃc from two sources (Source A and Source B) to a \\nsingle traﬃc mirror target\n","(Target D). After you create the traﬃc mirror session, any traﬃc that matches \\nthe ﬁlter rules is\n","encapsulated in a VXLAN header. It is then sent to the target.', metadata={'source': 'data/vpc-\n","tm.pdf', 'page': 6}), Document(page_content='Amazon Virtual Private Cloud Traﬃc Mirroring\\nTraﬃc\n","Mirroring concepts\\nWhat is Traﬃc Mirroring?\\nTraﬃc Mirroring is an Amazon VPC feature that you can\n","use to copy network traﬃc from an elastic \\nnetwork interface of type interface . You can then send\n","the traﬃc to out-of-band security and \\nmonitoring appliances for:\\n•Content inspection\\n•Threat\n","monitoring\\n•Troubleshooting\\nThe security and monitoring appliances can be deployed as individual\n","instances, or as a ﬂeet of instances \\nbehind either a Network Load Balancer or a Gateway Load\n","Balancer with a UDP listener. Traﬃc Mirroring \\nsupports ﬁlters and packet truncation, so that you\n","can extract only the traﬃc of interest, using the \\nmonitoring tools of your choice.\\nTraﬃc\n","Mirroring concepts\\nThe following are the key concepts for Traﬃc Mirroring:\\n•Source — The network\n","interface to monitor.\\n•Filter  — A set of rules that deﬁnes the traﬃc that is mirrored.\\n•Target —\n","The destination for mirrored traﬃc.', metadata={'source': 'data/vpc-tm.pdf', 'page': 4})]}\n","time: 6.06 s (started: 2023-11-21 16:06:47 +00:00)\n"]}],"source":["qa = RetrievalQA.from_chain_type(\n","    llm=llm,\n","    chain_type=\"stuff\",\n","    retriever=vectorstore_faiss.as_retriever(\n","        search_type=\"similarity\", search_kwargs={\"k\": 3}\n","    ),\n","    return_source_documents=True,\n","    chain_type_kwargs={\"prompt\": PROMPT}\n",")\n","answer = qa({\"query\": query})\n","print_ww(answer)"]},{"cell_type":"code","source":["print(answer['query'])\n","print(\"\\n\\n\")\n","print(answer['result'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WrEzZm6X25XW","executionInfo":{"status":"ok","timestamp":1700582814021,"user_tz":180,"elapsed":16,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"3267bf25-a319-4072-88c3-b52e0bb7a6cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["How does traffic mirroring works?\n","\n","\n","\n"," Based on the context, here is a summary of how traffic mirroring works in Amazon VPC:\n","\n","Traffic mirroring copies inbound and outbound traffic from network interfaces attached to instances. The mirrored traffic can be sent to the network interface of another instance, a Network Load Balancer with a UDP listener, or a Gateway Load Balancer with a UDP listener. \n","\n","The traffic mirror source and target can be in the same or different VPCs connected via VPC peering, transit gateway, or a Gateway Load Balancer. \n","\n","Traffic matching the mirroring filter rules is encapsulated in a VXLAN header and sent to the target. This allows out-of-band security and monitoring appliances to inspect, monitor, and troubleshoot the mirrored traffic.\n","time: 609 µs (started: 2023-11-21 16:06:53 +00:00)\n"]}]},{"cell_type":"markdown","source":["### Pergunta sobre Aurora"],"metadata":{"id":"zC81su-hjICQ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HdDhA70tW0Cv","executionInfo":{"status":"ok","timestamp":1700582827182,"user_tz":180,"elapsed":13175,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"069b32da-1e17-4b03-d77f-12f8068d47ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'query': 'What is the best database engine for Aurora?', 'result': ' Based on the provided context,\n","Aurora supports both MySQL and PostgreSQL database engines. Aurora is compatible with MySQL and\n","PostgreSQL and can deliver high throughput for both. The context does not indicate that one database\n","engine is better than the other for Aurora overall. So I don\\'t have enough information to\n","definitively say which database engine is \"best\" for Aurora in general. The choice between MySQL and\n","PostgreSQL depends on your specific application requirements and use case.', 'source_documents':\n","[Document(page_content='Aurora PostgreSQL or Aurora \\nMySQL. For supported engine \\nversions, see\n","Limitations of \\nAurora global databases .December 22, 2020\\n2500', metadata={'source':\n","'data/aurora-ug.pdf', 'page': 2518}), Document(page_content=\"Amazon Aurora User Guide for\n","Aurora\\nAmazon RDS shared responsibility model\\nWhat is Amazon Aurora?\\nAmazon Aurora (Aurora) is a\n","fully managed relational database engine t hat's compatible with MySQL \\nand PostgreSQL. You already\n","know how MySQL and PostgreSQL co mbine the speed and reliability of \\nhigh-end commercial databases\n","with the simplicity and cost-eﬀectivene ss of open-source databases. The \\ncode, tools, and\n","applications you use today with your existing MySQL and PostgreSQL databases can be \\nused with\n","Aurora. With some workloads, Aurora can deliver up to ﬁve  times the throughput of MySQL \\nand up to\n","three times the throughput of PostgreSQL with out requiring changes to most of your existing\n","\\napplications.\\nAurora includes a high-performance storage subsystem. Its MySQL - and PostgreSQL-\n","compatible \\ndatabase engines are customized to take advantage of that fast distribu ted storage.\n","The underlying\", metadata={'source': 'data/aurora-ug.pdf', 'page': 19}),\n","Document(page_content='Amazon Aurora User Guide for Aurora\\nSupported DB engines\\nNote\\nWe recommend\n","using the T DB instance classes only for develo pment, test, or other \\nnonproduction servers. For\n","more detailed recommendations for t he T instance classes, see Using \\nT instance classes for\n","development and testing  (p. 1160) .\\nFor DB instance class hardware speciﬁcations, see Hardware\n","speciﬁcations for DB instance classes for \\nAurora  (p. 92) .\\nSupported DB engines for DB instance\n","classes\\nIn the following table, you can ﬁnd details about supported Amaz on Aurora DB instance\n","classes for the \\nAurora DB engines.\\nInstance class Aurora MySQL Aurora PostgreSQL\\ndb.serverless –\n","Aurora Serverless v2 instance class with au tomatic capacity scaling\\ndb.serverless See Aurora\n","Serverless v2  (p. 52) See Aurora Serverless v2  (p. 52)\\ndb.x2g – memory-optimized instance classes\n","powered by AWS Graviton2 processors\\ndb.x2g.16xlarge 2.09.2 and higher, 2.10.0 and higher, \\n3.01.0\n","and higher15.2 and higher, 14.3 and higher, 13.3', metadata={'source': 'data/aurora-ug.pdf', 'page':\n","103})]}\n","time: 13.3 s (started: 2023-11-21 16:06:53 +00:00)\n"]}],"source":["query = \"What is the best database engine for Aurora?\"\n","answer = qa({\"query\": query})\n","print_ww(answer)"]},{"cell_type":"code","source":["print(answer['query'])\n","print(\"\\n\\n\")\n","print(answer['result'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xh36mI7rwX2L","executionInfo":{"status":"ok","timestamp":1700582827182,"user_tz":180,"elapsed":29,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"0936050d-f86d-4bd1-cae5-35c098a6e54b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["What is the best database engine for Aurora?\n","\n","\n","\n"," Based on the provided context, Aurora supports both MySQL and PostgreSQL database engines. Aurora is compatible with MySQL and PostgreSQL and can deliver high throughput for both. The context does not indicate that one database engine is better than the other for Aurora overall. So I don't have enough information to definitively say which database engine is \"best\" for Aurora in general. The choice between MySQL and PostgreSQL depends on your specific application requirements and use case.\n","time: 595 µs (started: 2023-11-21 16:07:06 +00:00)\n"]}]},{"cell_type":"markdown","source":["### Pergunta sobre DynamoDB"],"metadata":{"id":"uU6OZRP2jSfC"}},{"cell_type":"code","source":["query= \"How much does DynamoDB cost?\"\n","answer = qa({\"query\": query})\n","print_ww(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yl_j6VA-jVNC","executionInfo":{"status":"ok","timestamp":1700582839945,"user_tz":180,"elapsed":12788,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"2fee773d-1819-4db5-dce4-5766d53fde2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'query': 'How much does DynamoDB cost?', 'result': ' Based on the context provided, there are a few\n","ways to view the costs of DynamoDB:\\n\\n- The size of a DynamoDB table (and any indexes) contributes\n","to the monthly storage costs. This can be viewed in the console or via the DescribeTable API.\\n\\n-\n","For provisioned capacity tables, the read and write capacity units (RCUs and WCUs) contribute to the\n","throughput costs. These are returned by DescribeTable. However, costs can change if auto-scaling is\n","used.\\n\\n- For on-demand capacity tables, DescribeTable does not provide throughput cost\n","information, as these are based on actual usage per period, not provisioned capacity. \\n\\n- Usage of\n","DynamoDB Streams incurs charges based on the number of read requests made. The first 2.5 million\n","non-Lambda read requests per month are free. Costs are grouped at the region level in the billing\n","console.\\n\\n- There is no way', 'source_documents': [Document(page_content='Amazon DynamoDB\n","Developer Guide\\nCost optimization\\n•Amazon Kinesis Data Streams-based applications\\n•Customer\n","consumer applications built using an AWS SDK\\nRead requests made by AWS Lambda-based consumers of\n","DynamoDB Streams are free, whereas calls \\nmade by consumers of any other kind are charged. Every\n","month, the ﬁrst 2,500,000 read requests made \\nby non-Lambda consumers are also free of cost. This\n","applies to all read requests made to any DynamoDB \\nStreams in an AWS Account for each AWS\n","Region.\\nMonitoring your DynamoDB Streams usage\\nDynamoDB Streams charges on the billing console are\n","grouped together for all DynamoDB Streams \\nacross the AWS Region in an AWS Account. Currently,\n","tagging DynamoDB Streams is not supported, \\nso cost allocation tags cannot be used to identify\n","granular costs for DynamoDB Streams. The \\nvolume of GetRecords  calls can be obtained at the\n","DynamoDB Stream level to compute the \\ncharges per stream. The volume is represented by the DynamoDB\n","Stream’s CloudWatch metric', metadata={'source': 'data/dynamodb-dg.pdf', 'page': 1486}),\n","Document(page_content='How to view the costs of a single DynamoDB table\\nBoth the Amazon DynamoDB\n","AWS Management Console and the DescribeTable  API will show you \\ninformation about a single table,\n","including the primary key schema, any indexes on the table, and the \\nsize and item count of the\n","table and any indexes. The size of the table, plus the size of the indexes, can \\nbe used to\n","calculate the monthly storage cost for your table. For example, $0.25 per GB in the us-east-1\n","\\nregion.\\nIf the table is in provisioned capacity mode, the current RCU and WCU settings are\n","returned as well. \\nThese could be used to calculate the current read and write costs for the table,\n","but these costs could \\nchange, especially if the table has been conﬁgured with Auto\n","Scaling.\\nNote\\nIf the table is in on-demand capacity mode, then DescribeTable  will not help\n","estimate \\nthroughput costs, as these are billed based on actual, not provisioned usage in any one\n","period.\\nAPI Version 2012-08-10\\n1455', metadata={'source': 'data/dynamodb-dg.pdf', 'page': 1465}),\n","Document(page_content=\"Amazon DynamoDB Developer Guide\\nHigh availability and durability\\nWhat is\n","Amazon DynamoDB?\\nAmazon DynamoDB is a fully managed NoSQL database service that provides fast and\n","predictable \\nperformance with seamless scalability. DynamoDB lets you oﬄoad the administrative\n","burdens \\nof operating and scaling a distributed database so that you don't have to worry about\n","hardware \\nprovisioning, setup and conﬁguration, replication, software patching, or cluster scaling.\n","DynamoDB also \\noﬀers encryption at rest, which eliminates the operational burden and complexity\n","involved in protecting \\nsensitive data. For more information, see DynamoDB encryption at rest (p.\n","1333 ).\\nWith DynamoDB, you can create database tables that can store and retrieve any amount of\n","data and \\nserve any level of request traﬃc. You can scale up or scale down your tables' throughput\n","capacity \\nwithout downtime or performance degradation. You can use the AWS Management Console to\n","monitor\", metadata={'source': 'data/dynamodb-dg.pdf', 'page': 11})]}\n","time: 12.7 s (started: 2023-11-21 16:07:06 +00:00)\n"]}]},{"cell_type":"code","source":["print(answer['query'])\n","print(\"\\n\\n\")\n","print(answer['result'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eU4riRHz23s3","executionInfo":{"status":"ok","timestamp":1700582839945,"user_tz":180,"elapsed":16,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"6546b6ee-c659-47ba-dc1a-de9e6b064f66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["How much does DynamoDB cost?\n","\n","\n","\n"," Based on the context provided, there are a few ways to view the costs of DynamoDB:\n","\n","- The size of a DynamoDB table (and any indexes) contributes to the monthly storage costs. This can be viewed in the console or via the DescribeTable API.\n","\n","- For provisioned capacity tables, the read and write capacity units (RCUs and WCUs) contribute to the throughput costs. These are returned by DescribeTable. However, costs can change if auto-scaling is used.\n","\n","- For on-demand capacity tables, DescribeTable does not provide throughput cost information, as these are based on actual usage per period, not provisioned capacity. \n","\n","- Usage of DynamoDB Streams incurs charges based on the number of read requests made. The first 2.5 million non-Lambda read requests per month are free. Costs are grouped at the region level in the billing console.\n","\n","- There is no way\n","time: 514 µs (started: 2023-11-21 16:07:19 +00:00)\n"]}]},{"cell_type":"markdown","source":["### Pergunta sobre Amazon HealthLake"],"metadata":{"id":"b_bZXgxJL-wl"}},{"cell_type":"code","source":["query= \"How does Amazon HealthLake works?\"\n","answer = qa({\"query\": query})\n","print_ww(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j8kbrOYdMB6q","executionInfo":{"status":"ok","timestamp":1700582847925,"user_tz":180,"elapsed":7993,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"17ec51c6-1561-4349-b89b-a8647c0e72e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'query': 'How does Amazon HealthLake works?', 'result': \" Unfortunately I do not have enough\n","context to explain in detail how Amazon HealthLake works. Based on the provided background\n","information, Amazon HealthLake was not mentioned. Amazon EMR enables running big data frameworks\n","like Apache Hadoop and Apache Spark on AWS to process and analyze vast amounts of data, while Amazon\n","HealthLake is a HIPAA-eligible service that allows you to store, query, and analyze health data at\n","petabyte scale. To fully explain Amazon HealthLake's architecture and capabilities, I would need\n","more specific context about the service and how it is used. Without that additional context, I do\n","not have sufficient information to provide a concise explanation of how Amazon HealthLake works.\",\n","'source_documents': [Document(page_content='To use Amazon EMR, you launch a managed cluster of\n","Amazon EC2 instances running the Hadoop open \\nsource framework. Hadoop  is a distributed\n","application that implements the MapReduce algorithm, where \\na task is mapped to multiple nodes in\n","the cluster. Each node processes its designated work, in parallel \\nwith the other nodes. Finally,\n","the outputs are reduced on a single node, yielding the ﬁnal result.\\nYou can choose to launch your\n","Amazon EMR cluster so that it is persistent or transient:\\n•A persistent  cluster runs until you\n","shut it down. Persistent clusters are ideal for data analysis, data \\nwarehousing, or any other\n","interactive use.\\n•A transient  cluster runs long enough to process a job ﬂow, and then shuts down\n","automatically. \\nTransient clusters are ideal for periodic processing tasks, such as running\n","scripts.\\nFor information about Amazon EMR architecture and administration, see the Amazon EMR\n","Management \\nGuide .', metadata={'source': 'data/dynamodb-dg.pdf', 'page': 1556}),\n","Document(page_content='Guide .\\nWhen you launch an Amazon EMR cluster, you specify the initial\n","number and type of Amazon EC2 \\ninstances. You also specify other distributed applications (in\n","addition to Hadoop itself) that you want to \\nrun on the cluster. These applications include Hue,\n","Mahout, Pig, Spark, and more.\\nFor information about applications for Amazon EMR, see the Amazon EMR\n","Release Guide.\\nDepending on the cluster conﬁguration, you might have one or more of the following\n","node types:\\n•Leader node — Manages the cluster, coordinating the distribution of the MapReduce\n","executable and \\nsubsets of the raw data, to the core and task instance groups. It also tracks the\n","status of each task \\nperformed and monitors the health of the instance groups. There is only one\n","leader node in a cluster.\\nAPI Version 2012-08-10\\n1546', metadata={'source': 'data/dynamodb-\n","dg.pdf', 'page': 1556}), Document(page_content='compliance focused.\\n•Architecting for HIPAA\n","Security and Compliance on Amazon Web Services – This whitepaper describes \\nhow companies can use\n","AWS to create HIPAA-eligible applications.\\nAPI Version 2012-08-10\\n1388', metadata={'source':\n","'data/dynamodb-dg.pdf', 'page': 1398})]}\n","time: 8 s (started: 2023-11-21 16:07:19 +00:00)\n"]}]},{"cell_type":"code","source":["print(answer['query'])\n","print(\"\\n\\n\")\n","print(answer['result'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8oJE6j8UMCyB","executionInfo":{"status":"ok","timestamp":1700582847926,"user_tz":180,"elapsed":31,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"54347e47-f844-4213-d07a-9baeff4d6a09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["How does Amazon HealthLake works?\n","\n","\n","\n"," Unfortunately I do not have enough context to explain in detail how Amazon HealthLake works. Based on the provided background information, Amazon HealthLake was not mentioned. Amazon EMR enables running big data frameworks like Apache Hadoop and Apache Spark on AWS to process and analyze vast amounts of data, while Amazon HealthLake is a HIPAA-eligible service that allows you to store, query, and analyze health data at petabyte scale. To fully explain Amazon HealthLake's architecture and capabilities, I would need more specific context about the service and how it is used. Without that additional context, I do not have sufficient information to provide a concise explanation of how Amazon HealthLake works.\n","time: 694 µs (started: 2023-11-21 16:07:27 +00:00)\n"]}]},{"cell_type":"markdown","source":["### Pergunta sobre Amazon Kinesis"],"metadata":{"id":"5fd0JPInMGux"}},{"cell_type":"code","source":["query= \"How does Amazon Kinesis works?\"\n","answer = qa({\"query\": query})\n","print_ww(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yyqima7vMLb2","executionInfo":{"status":"ok","timestamp":1700582857216,"user_tz":180,"elapsed":9314,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"64419db0-c941-43dd-d8af-070a38d49400"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'query': 'How does Amazon Kinesis works?', 'result': ' Based on the context provided, Amazon\n","Kinesis Data Streams works with DynamoDB by capturing changes to data in a DynamoDB table and\n","sending them as records to a Kinesis data stream. When a Kinesis data stream is enabled for a\n","DynamoDB table, the table asynchronously sends out a data record for any creates, updates, or\n","deletes, including the time of the change, primary key, and images of the item before and after the\n","change. The stream records may arrive out of sequence or repeated. Kinesis data streams give access\n","to other services like Kinesis Data Firehose and Amazon Managed Apache Flink to build real-time\n","analytics and machine learning applications. Using Kinesis streams with DynamoDB incurs charges for\n","both Kinesis and DynamoDB.', 'source_documents': [Document(page_content='•An image of the item\n","before the modiﬁcation\\n•An image of the item after the modiﬁcation\\nThese data records are captured\n","and published in near-real time. After they are written to the Kinesis \\ndata stream, they can be\n","read just like any other record. You can use the Kinesis Client Library, use AWS \\nLambda, call the\n","Kinesis Data Streams API, and use other connected services. For more information, see\\nReading Data\n","from Amazon Kinesis Data Streams in the Amazon Kinesis Data Streams Developer Guide.\\nThese changes\n","to data are also captured asynchronously. Kinesis has no performance impact on a table \\nthat it’s\n","streaming from. The stream records stored in your Kinesis data stream are also encrypted at rest.\n","\\nFor more information, see Data Protection in Amazon Kinesis Data Streams.\\nThe Kinesis data stream\n","records might appear in a diﬀerent sequence than the item changes occurred. \\nThe same item\n","notiﬁcations might also appear more than once in the stream. You can check the', metadata={'source':\n","'data/dynamodb-dg.pdf', 'page': 647}), Document(page_content='Amazon DynamoDB Developer\n","Guide\\nWorking with Kinesis Data Streams\\nKinesis Data Streams also gives you access to Amazon\n","Kinesis Data Firehose and Amazon Managed \\nService for Apache Flink. These services can help you\n","build applications that power real-time dashboards, \\ngenerate alerts, implement dynamic pricing and\n","advertising, and implement sophisticated data analytics \\nand machine learning\n","algorithms.\\nNote\\nUsing Kinesis data streams for DynamoDB is subject to both Kinesis Data Streams\n","pricing for the \\ndata stream and DynamoDB pricing  for the source table.\\nHow Kinesis Data Streams\n","works with DynamoDB\\nWhen a Kinesis data stream is enabled for a DynamoDB table, the table sends out\n","a data record that \\ncaptures any changes to that table’s data. This data record includes:\\n•The\n","speciﬁc time any item was recently created, updated, or deleted\\n•That item’s primary key\\n•An image\n","of the item before the modiﬁcation\\n•An image of the item after the modiﬁcation',\n","metadata={'source': 'data/dynamodb-dg.pdf', 'page': 647}), Document(page_content='of activity is\n","collected and \\ntransmitted to Amazon Kinesis. \\nFrom Kinesis, you can monitor \\nthe activity stream\n","for further \\nanalysis. For more information, \\nsee Monitoring Amazon RDS \\nwith Database Activity\n","Streams.February 15, 2023\\n2821', metadata={'source': 'data/rds-ug.pdf', 'page': 2842})]}\n","time: 9.33 s (started: 2023-11-21 16:07:27 +00:00)\n"]}]},{"cell_type":"code","source":["print(answer['query'])\n","print(\"\\n\\n\")\n","print(answer['result'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e2v_hWXsMMFu","executionInfo":{"status":"ok","timestamp":1700582857216,"user_tz":180,"elapsed":27,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"216352a5-2994-419f-80c8-68b7b0d9d266"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["How does Amazon Kinesis works?\n","\n","\n","\n"," Based on the context provided, Amazon Kinesis Data Streams works with DynamoDB by capturing changes to data in a DynamoDB table and sending them as records to a Kinesis data stream. When a Kinesis data stream is enabled for a DynamoDB table, the table asynchronously sends out a data record for any creates, updates, or deletes, including the time of the change, primary key, and images of the item before and after the change. The stream records may arrive out of sequence or repeated. Kinesis data streams give access to other services like Kinesis Data Firehose and Amazon Managed Apache Flink to build real-time analytics and machine learning applications. Using Kinesis streams with DynamoDB incurs charges for both Kinesis and DynamoDB.\n","time: 722 µs (started: 2023-11-21 16:07:36 +00:00)\n"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mZqCsShcolf3","executionInfo":{"status":"ok","timestamp":1700582857216,"user_tz":180,"elapsed":25,"user":{"displayName":"Bruno Vilardi","userId":"08676047985655654406"}},"outputId":"f1a3d41a-efcc-4787-c9a0-b0b2b64036b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 8 ms (started: 2023-11-21 16:07:36 +00:00)\n"]}]}],"metadata":{"availableInstances":[{"_defaultOrder":0,"_isFastLaunch":true,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":4,"name":"ml.t3.medium","vcpuNum":2},{"_defaultOrder":1,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":8,"name":"ml.t3.large","vcpuNum":2},{"_defaultOrder":2,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.t3.xlarge","vcpuNum":4},{"_defaultOrder":3,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.t3.2xlarge","vcpuNum":8},{"_defaultOrder":4,"_isFastLaunch":true,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":8,"name":"ml.m5.large","vcpuNum":2},{"_defaultOrder":5,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.m5.xlarge","vcpuNum":4},{"_defaultOrder":6,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.m5.2xlarge","vcpuNum":8},{"_defaultOrder":7,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":64,"name":"ml.m5.4xlarge","vcpuNum":16},{"_defaultOrder":8,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":128,"name":"ml.m5.8xlarge","vcpuNum":32},{"_defaultOrder":9,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":192,"name":"ml.m5.12xlarge","vcpuNum":48},{"_defaultOrder":10,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":256,"name":"ml.m5.16xlarge","vcpuNum":64},{"_defaultOrder":11,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":384,"name":"ml.m5.24xlarge","vcpuNum":96},{"_defaultOrder":12,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":8,"name":"ml.m5d.large","vcpuNum":2},{"_defaultOrder":13,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.m5d.xlarge","vcpuNum":4},{"_defaultOrder":14,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.m5d.2xlarge","vcpuNum":8},{"_defaultOrder":15,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":64,"name":"ml.m5d.4xlarge","vcpuNum":16},{"_defaultOrder":16,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":128,"name":"ml.m5d.8xlarge","vcpuNum":32},{"_defaultOrder":17,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":192,"name":"ml.m5d.12xlarge","vcpuNum":48},{"_defaultOrder":18,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":256,"name":"ml.m5d.16xlarge","vcpuNum":64},{"_defaultOrder":19,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":384,"name":"ml.m5d.24xlarge","vcpuNum":96},{"_defaultOrder":20,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":true,"memoryGiB":0,"name":"ml.geospatial.interactive","supportedImageNames":["sagemaker-geospatial-v1-0"],"vcpuNum":0},{"_defaultOrder":21,"_isFastLaunch":true,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":4,"name":"ml.c5.large","vcpuNum":2},{"_defaultOrder":22,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":8,"name":"ml.c5.xlarge","vcpuNum":4},{"_defaultOrder":23,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.c5.2xlarge","vcpuNum":8},{"_defaultOrder":24,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.c5.4xlarge","vcpuNum":16},{"_defaultOrder":25,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":72,"name":"ml.c5.9xlarge","vcpuNum":36},{"_defaultOrder":26,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":96,"name":"ml.c5.12xlarge","vcpuNum":48},{"_defaultOrder":27,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":144,"name":"ml.c5.18xlarge","vcpuNum":72},{"_defaultOrder":28,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":192,"name":"ml.c5.24xlarge","vcpuNum":96},{"_defaultOrder":29,"_isFastLaunch":true,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.g4dn.xlarge","vcpuNum":4},{"_defaultOrder":30,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.g4dn.2xlarge","vcpuNum":8},{"_defaultOrder":31,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":64,"name":"ml.g4dn.4xlarge","vcpuNum":16},{"_defaultOrder":32,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":128,"name":"ml.g4dn.8xlarge","vcpuNum":32},{"_defaultOrder":33,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"hideHardwareSpecs":false,"memoryGiB":192,"name":"ml.g4dn.12xlarge","vcpuNum":48},{"_defaultOrder":34,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":256,"name":"ml.g4dn.16xlarge","vcpuNum":64},{"_defaultOrder":35,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":61,"name":"ml.p3.2xlarge","vcpuNum":8},{"_defaultOrder":36,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"hideHardwareSpecs":false,"memoryGiB":244,"name":"ml.p3.8xlarge","vcpuNum":32},{"_defaultOrder":37,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"hideHardwareSpecs":false,"memoryGiB":488,"name":"ml.p3.16xlarge","vcpuNum":64},{"_defaultOrder":38,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"hideHardwareSpecs":false,"memoryGiB":768,"name":"ml.p3dn.24xlarge","vcpuNum":96},{"_defaultOrder":39,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.r5.large","vcpuNum":2},{"_defaultOrder":40,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.r5.xlarge","vcpuNum":4},{"_defaultOrder":41,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":64,"name":"ml.r5.2xlarge","vcpuNum":8},{"_defaultOrder":42,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":128,"name":"ml.r5.4xlarge","vcpuNum":16},{"_defaultOrder":43,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":256,"name":"ml.r5.8xlarge","vcpuNum":32},{"_defaultOrder":44,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":384,"name":"ml.r5.12xlarge","vcpuNum":48},{"_defaultOrder":45,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":512,"name":"ml.r5.16xlarge","vcpuNum":64},{"_defaultOrder":46,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":768,"name":"ml.r5.24xlarge","vcpuNum":96},{"_defaultOrder":47,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.g5.xlarge","vcpuNum":4},{"_defaultOrder":48,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.g5.2xlarge","vcpuNum":8},{"_defaultOrder":49,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":64,"name":"ml.g5.4xlarge","vcpuNum":16},{"_defaultOrder":50,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":128,"name":"ml.g5.8xlarge","vcpuNum":32},{"_defaultOrder":51,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":256,"name":"ml.g5.16xlarge","vcpuNum":64},{"_defaultOrder":52,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"hideHardwareSpecs":false,"memoryGiB":192,"name":"ml.g5.12xlarge","vcpuNum":48},{"_defaultOrder":53,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"hideHardwareSpecs":false,"memoryGiB":384,"name":"ml.g5.24xlarge","vcpuNum":96},{"_defaultOrder":54,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"hideHardwareSpecs":false,"memoryGiB":768,"name":"ml.g5.48xlarge","vcpuNum":192},{"_defaultOrder":55,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"hideHardwareSpecs":false,"memoryGiB":1152,"name":"ml.p4d.24xlarge","vcpuNum":96},{"_defaultOrder":56,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"hideHardwareSpecs":false,"memoryGiB":1152,"name":"ml.p4de.24xlarge","vcpuNum":96}],"colab":{"provenance":[{"file_id":"1Qh-QwyQ7Zmm0iSPG36-jWEDbjIG9HEzX","timestamp":1700574070892}],"machine_shape":"hm"},"instance_type":"ml.t3.medium","kernelspec":{"display_name":"Python 3 (Data Science 3.0)","language":"python","name":"python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}